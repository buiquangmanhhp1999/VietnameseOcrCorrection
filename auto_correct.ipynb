{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "import itertools\n",
    "from nltk import ngrams\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from dataloader.dataset import BasicDataset, Collator\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from config import alphabet\n",
    "from optim.loss import LabelSmoothingLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        src: batch_size x time_step x number_class\n",
    "        outputs: batch_size x max_length x enc_hid_size ** 2\n",
    "        hidden: batch_size x hid_dim\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(src)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        hidden: batch_size x hid_dim\n",
    "        encoder_outputs: src_len x batch_size x hid_dim,\n",
    "        outputs: batch_size x src_len\n",
    "        \"\"\"\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attention = Attention(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size * 3, self.hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size * 4, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        embedded = self.embedding(inputs)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # caculate attention weight\n",
    "        attn_weights = self.attention(hidden, encoder_outputs)\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        \n",
    "        # apply attention weight to encoder output\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs)\n",
    "        attn_applied = attn_applied.permute(1, 0, 2)\n",
    "        \n",
    "        # decoder\n",
    "        rnn_input = torch.cat((embedded, attn_applied), 2)\n",
    "        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        attn_applied = attn_applied.squeeze(0)\n",
    "        \n",
    "        fc_input = torch.cat((output, attn_applied, embedded), dim=1)\n",
    "        prediction = self.fc_out(fc_input)\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, encoder_hidden, decoder_hidden, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, encoder_hidden, dropout)\n",
    "        self.decoder = AttnDecoderRNN(decoder_hidden, vocab_size)\n",
    "\n",
    "    def forward_encoder(self, src):\n",
    "        \"\"\"\n",
    "        src: timestep x batch_size x channel\n",
    "        hidden: batch_size x hid_dim\n",
    "        encoder_outputs: src_len x batch_size x hid_dim\n",
    "        \"\"\"\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        return hidden, encoder_outputs\n",
    "\n",
    "    def forward_decoder(self, tgt, memory):\n",
    "        \"\"\"\n",
    "        tgt: timestep x batch_size\n",
    "        hidden: batch_size x hid_dim\n",
    "        encoder: src_len x batch_size x hid_dim\n",
    "        output: batch_size x 1 x vocab_size\n",
    "        \"\"\"\n",
    "\n",
    "        tgt = tgt[-1]\n",
    "        hidden, encoder_outputs = memory\n",
    "        output, hidden, _ = self.decoder(tgt, hidden, encoder_outputs)\n",
    "        output = output.unsqueeze(1)\n",
    "\n",
    "        return output, (hidden, encoder_outputs)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \"\"\"\n",
    "        src: time_step x batch_size\n",
    "        trg: time_step x batch_size\n",
    "        outputs: batch_size x time_step x vocab_size\n",
    "        \"\"\"\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        device = src.device\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        for t in range(trg_len):\n",
    "            input = trg[t]\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            \n",
    "        outputs = outputs.transpose(0, 1).contiguous()\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(len(alphabet), encoder_hidden=256, decoder_hidden=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "valid_every = 1000\n",
    "print_every = 200\n",
    "lr = 0.01\n",
    "num_iters = 100000\n",
    "device = (\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optim.loss import LabelSmoothingLoss\n",
    "criterion = LabelSmoothingLoss(len(alphabet), 0).cpu()\n",
    "optimizer = AdamW(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-09)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=num_iters, pct_start=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5478334/5478334 [01:05<00:00, 84172.14it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = BasicDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# split train and val dataloader\n",
    "split_ratio = 0.99\n",
    "n_train = int(len(dataset) * split_ratio)\n",
    "n_val = len(dataset) - n_train\n",
    "train_dataset, val_dataset = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train data:  19566671\n",
      "The number of val data:  197644\n"
     ]
    }
   ],
   "source": [
    "print('The number of train data: ', n_train)\n",
    "print('The number of val data: ', n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
    "data_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import batch_to_device, cal_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    full_seq_acc_list = []\n",
    "    chars_acc_list = []\n",
    "    val_loss = 0,\n",
    "    val_acc = 0,\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            texts, tgt_input, tgt_output = batch\n",
    "            texts, tgt_input, tgt_output = batch_to_device(texts, tgt_input, tgt_output, device)\n",
    "            outputs = model(texts, tgt_input)\n",
    "            outputs = outputs.flatten(0, 1)\n",
    "            tgt_output = tgt_output.flatten()\n",
    "            loss = criterion(outputs, tgt_output)\n",
    "            # full_seq_acc, char_acc = cal_acc(outputs, tgt_input)\n",
    "            total_loss.append(loss.item())\n",
    "            # full_seq_acc_list.append(full_seq_acc)\n",
    "            # chars_acc_list.append(char_acc)\n",
    "            del outputs,\n",
    "            del loss,\n",
    "            \n",
    "    val_loss = np.mean(total_loss)\n",
    "#     full_seq_acc = np.mean(full_seq_acc_list)\n",
    "#     char_acc = np.mean(chars_acc_list)\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "#     return val_loss, full_seq_acc, char_acc\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    # get the inputs\n",
    "    texts, tgt_input, tgt_output = batch\n",
    "    texts, tgt_input, tgt_output = batch_to_device(texts, tgt_input, tgt_output, device)\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward + backward + optimize + scheduler\n",
    "    outputs = model(texts, tgt_input)\n",
    "    outputs = outputs.flatten(0, 1)\n",
    "    tgt_output = tgt_output.flatten()\n",
    "    loss = criterion(outputs, tgt_output)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    loss_item = loss.item()\n",
    "    \n",
    "    return loss_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 000200, train_loss: 1.8131, gpu_time: 0.532719612121582\n",
      "step: 000400, train_loss: 0.5177, gpu_time: 0.5884552001953125\n",
      "step: 000600, train_loss: 0.2962, gpu_time: 0.716571569442749\n",
      "step: 000800, train_loss: 0.2535, gpu_time: 0.6035690307617188\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-d3b0f1a1e4c5>\", line 22, in <module>\n",
      "    loss = train_step(batch)\n",
      "  File \"<ipython-input-16-6baebdb568ed>\", line 13, in train_step\n",
      "    loss.backward()\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/site-packages/torch/tensor.py\", line 198, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 100, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/manhbui/anaconda3/envs/manhbq/lib/python3.7/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d3b0f1a1e4c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-6baebdb568ed>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manhbq/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "total_loss = 0\n",
    "best_acc = 0\n",
    "best_loss = 1000\n",
    "global_step = 0\n",
    "weight_path = 'weight.pth'\n",
    "\n",
    "for i in range(num_iters):\n",
    "    model.train()\n",
    "    \n",
    "    try:\n",
    "        batch = next(data_iter)\n",
    "    except StopIteration:\n",
    "        data_iter = iter(train_loader)\n",
    "        batch = next(data_iter)\n",
    "    \n",
    "    texts, tgt_input, tgt_output = batch\n",
    "    global_step += 1\n",
    "    start = time.time()\n",
    "    try:\n",
    "        loss = train_step(batch)\n",
    "    except Exception:\n",
    "        print('max: ', tgt_input.cpu().numpy().max())\n",
    "    end = time.time()\n",
    "    total_loss += loss\n",
    "\n",
    "    if global_step % print_every == 0:\n",
    "        print('step: {:06d}, train_loss: {:.4f}, gpu_time: {}'.format(global_step, total_loss / print_every, end - start))\n",
    "        total_loss = 0\n",
    "        \n",
    "\n",
    "    if global_step % valid_every == 0:\n",
    "        # validate \n",
    "#         val_loss, full_seq_acc, char_acc = validate()\n",
    "        val_loss = validate()\n",
    "        print('================================')\n",
    "        print('val loss: ', val_loss)\n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), weight_path)\n",
    "            \n",
    "        print(\"==============================================================================\")\n",
    "        # print(\"val_loss: {:.4f}, full_seq_acc: {:.4f}, char_acc: {:.4f}\".format(val_loss, full_seq_acc, char_acc))\n",
    "        print(\"val_loss: {:.4f}\".format(val_loss))\n",
    "        print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('corpus-full.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mỗi cặp chỉ đẻ 1 quả trứng mỗi năm, có khi 2 năm, và 90% con non thường chết trong năm đầu tiên.Vì vậy, nhằm phục hồi số lượng kền kền, chìa khóa thành công bao gồm việc thuyết phục mọi người rằng đây là lợi ích lâu dài của chính họ và bảo vệ các con trưởng thành khỏi nguồn chất độc.\\xa0Các đơn vị bảo tồn trên khắp châu Phi đang phối hợp với nhau, tập trung tập huấn cho lực lượng chức năng và kiểm lâm, nhanh chóng loại bỏ các xác động vật bị nhiễm độc - vốn không phải là chuyện dễ giữa một diện tích rộng lớn như vậy.Các chương trình giáo dục cho cộng đồng nông thôn và thúc đẩy thay đổi cơ sở hạ tầng là những cách tiếp cận dài hạn.\\xa0Tổ chức Bảo tồn Nigeria đang làm việc cùng hơn 80 \"thầy lang\" địa phương để thay đổi quan niệm dùng kền kền chữa bệnh\\n',\n",
       " 'Tất cả các quốc gia châu Phi có kền kền sinh sống đã thống nhất một kế hoạch hành động lâu dài để bảo tồn loài chim này, trong đó có hẳn một lộ trình cho 12 năm tới.\\xa0Học hỏi các kế hoạch tương tự ở châu Á, các tổ chức bảo tồn miền nam châu Phi đã \"liên minh\" xây dựng một loạt \"khu vực an toàn cho kền kền\", mở \"nhà hàng cho kền kền\", các bãi đất để trữ xác động vật cho loài chim ưa xác thối này.Tin vui là 3 trong số 4 loài kền kền được tìm thấy ở châu Âu đang gia tăng số lượng\\n',\n",
       " 'Kền kền đang giúp EU tiết kiệm hàng triệu euro mỗi năm nhờ giảm nhu cầu thiêu hủy động vật chết, giảm công vận chuyển và giảm cả lượng khí thải CO2.Còn tại Bắc Mỹ, kền kền California đã \"lội ngược dòng\" ngoạn mục\\n',\n",
       " '22 cá thể còn sót lại năm 1982 đã sinh sôi phát triển thành 1.000 con (tính đến giữa năm 2019) nhờ sự hỗ trợ ấp nở của Tổ chức Peregrine Fund (Mỹ).Cambuchia, nơi được xem là \"thành trì\" cuối cùng của loài kền kền ở Đông Nam Á, mới đây vừa công bố ghi nhận được 119 cá thể kền kền trong các khu bảo tồn tự nhiên\\n',\n",
       " 'Du lịch dù lượn trên không cùng kền kền ở Nepal TTO - “Thú vị, tuyệt vời, huyền diệu” là những gì mà du khách cảm nhận trong chuyến du ngoạn dù lượn trên không cùng chú chim kền kền Ai Cập xinh đẹp tại Nepal.\\n',\n",
       " 'Môn khoa học tự nhiên tích hợp 3 môn vật lý, hóa học và sinh học; môn lịch sử và địa lý tích hợp 2 môn lịch sử và địa lý\\n',\n",
       " 'Điều này gây lo lắng cho giáo viên (GV) đang giảng dạy các môn lý, hóa, sinh, sử và địa\\n',\n",
       " 'Vì vậy, cần có kế hoạch bồi dưỡng một cách hợp lý, hiệu quả cao nhưng không làm quá tải đối với GV.\\n',\n",
       " 'Rất ít giáo viên dạy tất cả các phân môn trong môn tích hợp\\n',\n",
       " 'Để phục vụ đổi mới chương trình giáo dục phổ thông, Viện Nghiên cứu giáo dục, Trường ĐH Sư phạm TP.HCM triển khai một số đề tài liên quan đến đội ngũ GV phổ thông\\n']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112921289"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = list(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305067"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) - len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('train_data.txt', 'w')\n",
    "file.writelines(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112616222"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manhbq",
   "language": "python",
   "name": "manhbq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
